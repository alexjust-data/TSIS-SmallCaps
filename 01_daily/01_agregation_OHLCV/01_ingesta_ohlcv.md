# Pipeline de Ingesta Trades Tick-Level

1. [Descarga Trades 2004-2025 (6,405 tickers)](#descarga-trades-tick-level-2004-2025---6405-tickers)
2. [AuditorÃ­a de Descarga](#auditoria-de-descarga-en-progreso)
3. [VisualizaciÃ³n del Pipeline](#route-map---pipeline-completo)

---

## Route Map - Pipeline Completo

```bash
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    PIPELINE DE INGESTA TRADES TICK-LEVEL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PASO 0: UNIVERSO SMALL CAPS (DESDE FASE A)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input: processed/universe/smallcaps_universe_2025-11-01.parquet

        ğŸ¯ UNIVERSO TARGET: 6,405 tickers
        â”œâ”€ Activos (< $2B): 3,105 (48.5%)
        â””â”€ Inactivos preservados: 3,300 (51.5%)
           â†’ âœ… ANTI-SURVIVORSHIP BIAS APLICADO


                          â†“  DESCARGA HISTÃ“RICA


PASO 1: DESCARGA INICIAL 2019-2025 (COMPLETADA)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Script: batch_trades_wrapper.py + ingest_trades_ticks.py
PerÃ­odo: 2019-01-01 â†’ 2025-11-01 (7 aÃ±os)
Output: C:\TSIS_Data\trades_ticks_2019_2025\

        ğŸ“Š DESCARGA 2019-2025: COMPLETADA (2025-11-09)
        â”œâ”€ Tickers descargados: 6,274/6,405 (97.95%)
        â”œâ”€ Tiempo total: ~36 horas continuas
        â”œâ”€ Velocidad promedio: 300-350 tickers/hora
        â”œâ”€ TamaÃ±o: 100.41 GB (comprimido ZSTD level 1)
        â””â”€ Errores HTTP 429: 0

        ConfiguraciÃ³n usada:
        â”œâ”€ Batch size: 60 tickers
        â”œâ”€ Max concurrent: 50 batches
        â”œâ”€ Rate limit: 0.05s (600 req/s teÃ³rico)
        â””â”€ Con --resume (idempotente)


                          â†“  PROBLEMA DETECTADO


PASO 2: AUDITORÃA DE --resume (2025-11-10)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Script: audit_download_complete.py
Hallazgo: --resume SALTA tickers con datos existentes

        âš ï¸  PROBLEMA IDENTIFICADO:
        â”œâ”€ --resume verifica: Â¿Tiene ALGÃšN parquet?
        â”‚   â””â”€ SI â†’ SALTA ticker completamente
        â”‚   â””â”€ NO â†’ Descarga 2004-2025
        â”‚
        â”œâ”€ Consecuencia:
        â”‚   â”œâ”€ 6,274 tickers con datos 2019-2025
        â”‚   â””â”€ NO descargarÃ­an aÃ±os 2004-2018
        â”‚
        â””â”€ SoluciÃ³n: Lanzar SIN --resume para 2004-2018


                          â†“  CORRECCIÃ“N APLICADA


PASO 3: DESCARGA EXPANDIDA 2004-2018 (EN PROGRESO)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Inicio: 2025-11-11 08:38:49
Proceso ID: 126815
Script: batch_trades_wrapper.py (SIN --resume)
PerÃ­odo: 2004-01-01 â†’ 2018-12-31 (15 aÃ±os)
Output: C:\TSIS_Data\trades_ticks_2019_2025\ (misma carpeta)

        ğŸ”„ DESCARGA 2004-2018: EN PROGRESO
        â”œâ”€ Tickers procesando: 6,405 (TODOS)
        â”œâ”€ Batches totales: 107 batches Ã— 60 tickers
        â”œâ”€ Concurrencia: 50 batches simultÃ¡neos
        â”œâ”€ Merge automÃ¡tico: âœ… (sin duplicados)
        â””â”€ Tiempo estimado: ~18-22 horas

        ConfiguraciÃ³n actual:
        â”œâ”€ Batch size: 60 tickers
        â”œâ”€ Max concurrent: 50 batches
        â”œâ”€ Rate limit: 0.05s (600 req/s teÃ³rico)
        â””â”€ SIN --resume (procesa todos los tickers)

        Merge automÃ¡tico verificado:
        â”œâ”€ FunciÃ³n: write_trades_by_day() (lÃ­neas 223-271)
        â”œâ”€ LÃ³gica: Si archivo existe:
        â”‚   â”œâ”€ Lee archivo existente
        â”‚   â”œâ”€ Concatena nuevos datos
        â”‚   â”œâ”€ Elimina duplicados por timestamp
        â”‚   â”œâ”€ Mantiene Ãºltimo valor (keep="last")
        â”‚   â””â”€ Sobrescribe archivo
        â””â”€ âœ… IDEMPOTENTE: Puede interrumpirse y relanzarse


                          â†“  RESULTADO ESPERADO


PASO 4: RESULTADO FINAL (ETA: 2025-11-12)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Output: C:\TSIS_Data\trades_ticks_2019_2025\

        ğŸ‰ COBERTURA COMPLETA: 6,405 tickers Ã— 22 aÃ±os
        â”œâ”€ AÃ±os 2004-2018: 15 aÃ±os histÃ³ricos
        â”œâ”€ AÃ±os 2019-2025: 7 aÃ±os recientes
        â”œâ”€ TamaÃ±o estimado: ~250-300 GB (comprimido)
        â””â”€ Espacio usado: ~800 GB disponibles

        DistribuciÃ³n de datos:
        â”œâ”€ Trades totales: Miles de millones
        â”œâ”€ PerÃ­odo: 2004-01-01 â†’ 2025-11-01
        â”œâ”€ Archivos/ticker: ~5,500 (22 aÃ±os Ã— 250 dÃ­as)
        â””â”€ Estructura: ticker/year=YYYY/month=MM/day=DD/[session].parquet


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… DESCARGA EN PROGRESO - ETA 18-22 HORAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RESULTADO ESPERADO: 6,405 tickers con cobertura 2004-2025
â”œâ”€ PerÃ­odo completo: 22 aÃ±os (2004-2025)
â”œâ”€ TamaÃ±o total: ~250-300 GB comprimidos
â”œâ”€ Merge automÃ¡tico: Sin duplicados
â””â”€ Listo para: AnÃ¡lisis de microestructura 2004-2025

READY FOR: Feature Engineering & ML Training
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## Descarga Trades Tick-Level 2004-2025 - 6,405 tickers

* **Objetivo**: Descargar trades tick-level histÃ³ricos (2004-2025) para 6,405 tickers Small Caps. Este proceso descarga trades individuales con separaciÃ³n premarket/market para anÃ¡lisis de microestructura y liquidez.
* **Fuente de datos**: Polygon API `/v3/trades/{ticker}` (timestamp-based)
* **Script principal**: [scripts/01_agregation_OHLCV/ingest_trades_ticks.py](../../scripts/01_agregation_OHLCV/ingest_trades_ticks.py)
* **Wrapper**: [scripts/01_agregation_OHLCV/batch_trades_wrapper.py](../../scripts/01_agregation_OHLCV/batch_trades_wrapper.py)
* **Output**: [C:\TSIS_Data\trades_ticks_2019_2025\](C:\TSIS_Data\trades_ticks_2019_2025\)

```bash
D:\TSIS_SmallCaps\
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ 01_agregation_OHLCV/
â”‚       â”œâ”€â”€ ingest_trades_ticks.py          # Core: Descarga diaria + separaciÃ³n premarket/market
â”‚       â””â”€â”€ batch_trades_wrapper.py         # Wrapper: Micro-batches + paralelismo
â”‚
â”œâ”€â”€ processed/universe/
â”‚   â””â”€â”€ smallcaps_universe_2025-11-01.parquet   # 6,405 tickers Small Caps
â”‚
â””â”€â”€ C:\TSIS_Data\
    â””â”€â”€ trades_ticks_2019_2025/             # OUTPUT FINAL
        â”œâ”€â”€ _batch_temp/                    # Logs temporales de batches
        â”‚   â”œâ”€â”€ batch_0000.csv              # Lista de tickers por batch
        â”‚   â”œâ”€â”€ batch_0000.log              # Log de progreso
        â”‚   â””â”€â”€ batch_XXXX.log              # 107 batches totales
        â”‚
        â””â”€â”€ {TICKER}/                       # 6,405 tickers
            â””â”€â”€ year={YYYY}/                # 22 aÃ±os (2004-2025)
                â””â”€â”€ month={MM}/             # 12 meses
                    â””â”€â”€ day={YYYY-MM-DD}/   # ~250 dÃ­as/aÃ±o
                        â”œâ”€â”€ premarket.parquet    # 04:00-09:30 ET
                        â””â”€â”€ market.parquet       # 09:30-16:00 ET
```

**Comando de ejecuciÃ³n (ACTUAL - EN PROGRESO):**

```bash
cd "D:\TSIS_SmallCaps" && python scripts/01_agregation_OHLCV/batch_trades_wrapper.py \
    --tickers-csv processed/universe/smallcaps_universe_2025-11-01.parquet \
    --outdir "C:\TSIS_Data\trades_ticks_2019_2025" \
    --from 2004-01-01 \
    --to 2018-12-31 \
    --batch-size 60 \
    --max-concurrent 50 \
    --rate-limit 0.05 \
    --ingest-script scripts/01_agregation_OHLCV/ingest_trades_ticks.py
    # SIN --resume para descargar aÃ±os faltantes
```

```sh
ğŸ“Š 1. Estructura de datos descargados
----------------------------------------------------------------------------------------------------
Ejemplo ticker GGL con datos 2006-2008:

C:\TSIS_Data\trades_ticks_2019_2025\GGL\
â”œâ”€â”€ year=2006\
â”‚   â””â”€â”€ month=04\
â”‚       â””â”€â”€ day=2006-04-06\
â”‚           â””â”€â”€ market.parquet              # 153,238 trades (09:30-16:00 ET)
â”‚   â””â”€â”€ month=05\
â”‚       â””â”€â”€ day=2006-05-01\
â”‚           â”œâ”€â”€ premarket.parquet           # Trades 04:00-09:30 ET
â”‚           â””â”€â”€ market.parquet              # Trades 09:30-16:00 ET
â”œâ”€â”€ year=2007\
â””â”€â”€ year=2008\

Columnas en cada parquet:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ticker â”† date      â”† timestamp           â”† price â”† size â”† exchange â”† conditions  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GGL    â”†2006-04-06 â”†1144318200000000000 â”† 15.20 â”† 100  â”† Q        â”† [@, T, I]   â”‚
â”‚ GGL    â”†2006-04-06 â”†1144318201234567890 â”† 15.21 â”† 200  â”† Q        â”† [@, T]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š 2. ConfiguraciÃ³n tÃ©cnica (ingest_trades_ticks.py)
----------------------------------------------------------------------------------------------------
BASE_URL = "https://api.polygon.io"
PAGE_LIMIT = 50000                    # Trades por pÃ¡gina
TIMEOUT = 45                          # Segundos
RETRY_MAX = 8                         # Reintentos
BACKOFF = 1.6                         # Factor exponencial
COMPRESSION = "zstd"                  # CompresiÃ³n
COMPRESSION_LEVEL = 1                 # Nivel (1-22)

Horarios de mercado (ET):
  PREMARKET:  04:00 - 09:30 ET  â†’ premarket.parquet
  MARKET:     09:30 - 16:00 ET  â†’ market.parquet

ğŸ“Š 3. ConfiguraciÃ³n tÃ©cnica (batch_trades_wrapper.py)
----------------------------------------------------------------------------------------------------
BATCH_SIZE = 60                       # Tickers por batch
MAX_CONCURRENT = 50                   # Batches simultÃ¡neos
RATE_LIMIT = 0.05                     # Segundos entre requests (600 req/s)
```

## AuditorÃ­a de Descarga (EN PROGRESO)

* **Objetivo**: Verificar integridad de descarga, detectar problemas con --resume, y monitorear velocidad de descarga en tiempo real.
* **Script**: [scripts/audit_download_complete.py](../../scripts/audit_download_complete.py)
* **Uso**: Ejecutar periÃ³dicamente durante descarga larga para verificar progreso y detectar bloqueos.

**Comando de ejecuciÃ³n:**

```bash
python D:\TSIS_SmallCaps\scripts\audit_download_complete.py
```

**Verificaciones realizadas:**

```sh
====================================================================================================
AUDITORÃA - VERIFICACIONES AUTOMÃTICAS
====================================================================================================

1. Estado del proceso
   - Â¿EstÃ¡ corriendo?
   - Â¿CuÃ¡ndo fue Ãºltima actualizaciÃ³n de logs?
   - Â¿QuÃ© batches estÃ¡n activos?

2. Funcionamiento de --resume
   - Â¿CÃ³mo decide quÃ© tickers saltar?
   - Â¿Verifica aÃ±os especÃ­ficos o solo existencia de datos?
   - Impacto en descarga expandida 2004-2025

3. Velocidad de descarga
   - MB/minuto escribiÃ©ndose a disco
   - API requests/minuto a Polygon
   - Trades/minuto descargados

4. AÃ±os descargados por ticker
   - Sample de tickers recientemente modificados
   - Â¿QuÃ© rango temporal tiene cada ticker?
   - Â¿Faltan aÃ±os 2004-2018 en tickers existentes?

5. Errores en logs
   - HTTP 429 (rate limit)
   - HTTP 500/503 (servidor)
   - Excepciones Python
```

**Ejemplo de output:**

```sh
================================================================================
AUDITORÃA COMPLETA - DESCARGA TRADES TICK-LEVEL 2004-2025
================================================================================

1. ESTADO DEL PROCESO
--------------------------------------------------------------------------------
OK PROCESO ACTIVO - Logs modificados recientemente:
   Batch 0000: ultima actualizacion hace 37s (08:31:47)
   Batch 0001: ultima actualizacion hace 9s (08:32:16)

2. FUNCIONAMIENTO DE --resume
--------------------------------------------------------------------------------
LOGICA: Si un ticker tiene CUALQUIER archivo parquet (de cualquier anio),
        entonces --resume lo marca como 'completado' y lo SALTA.

CONSECUENCIA:
  [OK] Tickers con datos 2019-2025 -> NO se re-descargan esos anios
  [OK] Tickers con datos 2019-2025 -> NO se descargan anios 2004-2018
  [OK] Solo descarga los 131 tickers sin ningun dato previo

SOLUCION ACTUAL:
  Lanzar SIN --resume para descargar aÃ±os 2004-2018 en todos los tickers
  Merge automÃ¡tico evita duplicados en aÃ±os 2019-2025

3. VELOCIDAD DE DESCARGA (ÃšLTIMOS 5 MINUTOS)
--------------------------------------------------------------------------------
Archivos creados/modificados: 45
Datos escritos: 12.34 MB
Velocidad: 2.47 MB/minuto (148.2 MB/hora)

Ultimos 10 archivos:
  08:32:15 |   245.3 KB | GGL/year=2007/month=03/day=2007-03-15/market.parquet
  08:32:10 |   198.7 KB | GGL/year=2007/month=03/day=2007-03-14/market.parquet
  08:32:05 |   312.1 KB | GGL/year=2007/month=03/day=2007-03-13/market.parquet

4. REQUESTS A POLYGON API (ÃšLTIMOS 5 MINUTOS)
--------------------------------------------------------------------------------
Actualizaciones de progreso: 42 (ultimos 5 minutos)
Velocidad estimada: ~8.4 actualizaciones/minuto

Por batch:
  Batch 0000: 22 actualizaciones
  Batch 0001: 20 actualizaciones

ALERTA  Cada actualizacion = ~200 API requests a Polygon
   Total estimado: ~8,400 requests en 5 minutos
   Rate: ~28.0 requests/segundo

5. COBERTURA DE AÃ‘OS POR TICKER
--------------------------------------------------------------------------------
Tickers modificados en Ãºltimos 5 minutos:
  GGL        |  3 aÃ±os (2006-2008) | 08:17:29
  SMTK       |  7 aÃ±os (2019-2025) | 07:24:47
  STBZ       |  7 aÃ±os (2019-2025) | 05:55:58

6. VERIFICACIÃ“N --resume CON TICKER EXISTENTE
--------------------------------------------------------------------------------
Ticker: AAPL
AÃ±os existentes: 2019, 2020, 2021, 2022, 2023, 2024, 2025
Total aÃ±os: 7

Desglose:
  2004-2018: 0 aÃ±os â†’ NINGUNO
  2019-2025: 7 aÃ±os â†’ ['2019', '2020', '2021', '2022', '2023', '2024', '2025']

ALERTA  CONFIRMADO: AAPL tiene 2019-2025 pero NO 2004-2018
   --resume lo SALTO porque ya tiene datos

7. ERRORES EN LOGS (ÃšLTIMAS 100 LÃNEAS)
--------------------------------------------------------------------------------
OK No se encontraron errores en logs recientes

================================================================================
RESUMEN DE AUDITORÃA
================================================================================

[OK] PROCESO: ACTIVO
[OK] Velocidad: 2.47 MB/minuto (normal para aÃ±os histÃ³ricos)
[OK] API Requests: ~8,400 en ultimos 5 min
[OK] Sin errores HTTP 429 o 500
[OK] Merge automÃ¡tico funcionando (sin duplicados)

================================================================================
```

## HistÃ³rico de Comandos Ejecutados

```bash
# COMANDO 1: Descarga inicial 2019-2025 con --resume (COMPLETADA 2025-11-09)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cd "D:\TSIS_SmallCaps" && python scripts/01_agregation_OHLCV/batch_trades_wrapper.py \
    --tickers-csv processed/universe/smallcaps_universe_2025-11-01.parquet \
    --outdir "C:\TSIS_Data\trades_ticks_2019_2025" \
    --from 2019-01-01 \
    --to 2025-11-01 \
    --batch-size 60 \
    --max-concurrent 50 \
    --rate-limit 0.05 \
    --ingest-script scripts/01_agregation_OHLCV/ingest_trades_ticks.py \
    --resume

Resultado:
  âœ… 6,274/6,405 tickers descargados (97.95%)
  âœ… 100.41 GB comprimidos (ZSTD level 1)
  âœ… ~36 horas tiempo total
  âœ… 300-350 tickers/hora velocidad promedio
  âœ… 0 errores HTTP 429


# COMANDO 2: Intento expansiÃ³n 2004-2025 con --resume (MATADO 2025-11-10)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cd "D:\TSIS_SmallCaps" && python scripts/01_agregation_OHLCV/batch_trades_wrapper.py \
    --tickers-csv processed/universe/smallcaps_universe_2025-11-01.parquet \
    --outdir "C:\TSIS_Data\trades_ticks_2019_2025" \
    --from 2004-01-01 \
    --to 2025-11-01 \
    --batch-size 60 \
    --max-concurrent 50 \
    --rate-limit 0.05 \
    --ingest-script scripts/01_agregation_OHLCV/ingest_trades_ticks.py \
    --resume

Proceso ID: 06d021
Tiempo ejecutado: 11.7 horas
Motivo de terminaciÃ³n: PROBLEMA DETECTADO

Problema:
  âš ï¸  --resume saltÃ³ 6,274 tickers con datos 2019-2025
  âš ï¸  Solo procesÃ³ 131 tickers sin datos previos
  âš ï¸  Velocidad: 14 tickers/hora (21.4x mÃ¡s lento, warrants sin trades)

AcciÃ³n tomada:
  ğŸ”´ Proceso matado a las 08:38:49 (2025-11-11)


# COMANDO 3: Descarga 2004-2018 SIN --resume (EN PROGRESO 2025-11-11)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cd "D:\TSIS_SmallCaps" && python scripts/01_agregation_OHLCV/batch_trades_wrapper.py \
    --tickers-csv processed/universe/smallcaps_universe_2025-11-01.parquet \
    --outdir "C:\TSIS_Data\trades_ticks_2019_2025" \
    --from 2004-01-01 \
    --to 2018-12-31 \
    --batch-size 60 \
    --max-concurrent 50 \
    --rate-limit 0.05 \
    --ingest-script scripts/01_agregation_OHLCV/ingest_trades_ticks.py
    # SIN --resume

Proceso ID: 126815
Inicio: 2025-11-11 08:38:49
Estado: ACTIVO

Estrategia:
  âœ… Descargar SOLO aÃ±os 2004-2018
  âœ… Para TODOS los 6,405 tickers
  âœ… Merge automÃ¡tico evita duplicados en 2019-2025
  âœ… ETA: ~18-22 horas
```

## Resumen de MÃ©tricas

```sh
====================================================================================================
ğŸ“Š FASE 1: DESCARGA 2019-2025 (COMPLETADA)
====================================================================================================
Inicio:                   2025-11-08 ~12:00
Fin:                      2025-11-09 ~00:00
Tiempo total:             ~36 horas continuas
Velocidad promedio:       300-350 tickers/hora
Tickers procesados:       6,274/6,405 (97.95%)
Errores HTTP 429:         0 (rate limit perfecto)
TamaÃ±o descargado:        100.41 GB (comprimido ZSTD level 1)

ConfiguraciÃ³n:
  - PerÃ­odo: 2019-01-01 â†’ 2025-11-01 (7 aÃ±os)
  - Batch size: 60 tickers
  - Max concurrent: 50 batches
  - Rate limit: 0.05s (600 req/s teÃ³rico)
  - Con --resume: âœ…

Completitud:
  - Tickers completos: 2,760 (43.09%)
  - Tickers parciales: 3,514 (56.04%)
  - Sin datos: 131 (2.05%)


====================================================================================================
ğŸ“Š FASE 2: DESCARGA 2004-2018 (EN PROGRESO)
====================================================================================================
Inicio:                   2025-11-11 08:38:49
Proceso ID:               126815
Estado:                   ACTIVO
Tickers procesando:       6,405 (TODOS)
Batches totales:          107 batches Ã— 60 tickers
Tiempo transcurrido:      ~1 hora
Tiempo estimado restante: ~18-22 horas

ConfiguraciÃ³n:
  - PerÃ­odo: 2004-01-01 â†’ 2018-12-31 (15 aÃ±os)
  - Batch size: 60 tickers
  - Max concurrent: 50 batches
  - Rate limit: 0.05s (600 req/s teÃ³rico)
  - Sin --resume: âœ…

Merge automÃ¡tico:
  - FunciÃ³n: write_trades_by_day() (ingest_trades_ticks.py:223-271)
  - LÃ³gica: Concatena + unique(subset=["timestamp"], keep="last")
  - Resultado: Sin duplicados en aÃ±os 2019-2025 existentes


====================================================================================================
ğŸ“Š RESULTADO FINAL ESPERADO (ETA: 2025-11-12)
====================================================================================================
AÃ±os 2004-2018:           ~150-200 GB (estimado)
AÃ±os 2019-2025:           100.41 GB (ya descargado)
TOTAL ESPERADO:           ~250-300 GB (22 aÃ±os completos)
Espacio disponible:       800 GB (suficiente con margen)

Trades estimados:
  - Total trades: Miles de millones
  - Promedio/ticker-aÃ±o: ~5-10 millones de trades
  - Variabilidad: Alta (small caps tienen menos volumen)

Archivos por ticker:
  - Total archivos: ~5,500 (22 aÃ±os Ã— 250 dÃ­as trading)
  - Premarket.parquet: ~2,750 archivos
  - Market.parquet: ~2,750 archivos

Promedio por ticker:
  - TamaÃ±o: ~40-50 MB (22 aÃ±os comprimidos)
  - Trades: ~100-200 millones (lifetime)
```

## Monitoreo en Tiempo Real

```bash
# Ver progreso del wrapper principal
tail -f C:/TSIS_Data/trades_ticks_2019_2025/_batch_temp/batch_0000.log

# Ver batches activos recientemente
ls -lah C:/TSIS_Data/trades_ticks_2019_2025/_batch_temp/ | grep "nov. 11"

# Contar archivos descargados por ticker
find C:/TSIS_Data/trades_ticks_2019_2025/GGL -name "*.parquet" | wc -l

# Ver Ãºltimos archivos creados (Ãºltimos 5 minutos)
find C:/TSIS_Data/trades_ticks_2019_2025 -name "*.parquet" -mmin -5 | head -20

# Ejecutar auditorÃ­a completa
python D:\TSIS_SmallCaps\scripts\audit_download_complete.py
```

---
